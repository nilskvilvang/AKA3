---
bibliography: bibliografi.bib  
csl: chicago-author-date.csl
always_allow_html: true
---
# T-tester

R-pakker brukt i dette kapittelet:

```{r}
pacman::p_load(tidyverse, readxl, summarytools, ggpubr, nortest, tseries)
```

En t-test brukes når man vil sammenlikne to gjennomsnittsverdier og utvalget er relativt lite. Vi kan se for oss tre tilfeller:

Vi sammenlikner en gruppe mot en kjent gjennomsnittsstørelse og tester om gruppas gjennomsnitt er signifikant forskjellig fra det kjente gjennomsnittet («One sample t-test»).
Vi sammenlikner to uavhengige gruppers gjennomsnitt for å se om det er signifikant forskjell på gjennomsnittene for en variabel («Independent samples t-test»)
Vi sammenlikner samme gruppe på to ulike tidspunkt – observasjonene er altså ikke uavhengige av hverandre («Paired samples t-test»)
En t-test handler altså om å undersøke om det er signifikant forskjell på gjennomsnittsverdiene i to sett med data. Vi setter derfor opp en nullhypotese som sier at det ikke er forskjell:

$H_0: \mu_1 = \mu_2$

Hvis vi denne nullhypotesen ikke kan forkastes (at vi konkluderer med at gjennomsnittene er like) betyr det for eksempel at en gruppe som har fått «ekte» medisin ikke skiller seg fra en gruppe som har fått placebo. Hvis vi derimot forkaster nullhypotesen vil vi konkludere med at det er signifikant forskjell mellom de to gruppene (på en eller annen verdi vi måler). T-testen tester denne nullhypotesen – at det ikke er forskjell.

I en t-test får vi en testverdi. Dersom p-verdien for denne testen er mindre enn 0.05 (gitt at vi bruker $\alpha = 0.05$) forkaster vi nullhypotesen (If p is low, the null must go»), og vi vil anta at det er signifikant forskjell mellom gruppene (og at denne forskjellen ikke skyldes tilfeldigheter). Er p høyere enn valgt α vil vi beholde nullhypotesen.

## Students t-test

T-test, eller "Student’s t-test" som den ofte omtales som, baserer seg på en såkalt t-fordeling. En t-fordeling er ganske lik en normaldistribusjon, men har tyngre haler. Fordelingen vil variere med antall frihetsgrader, men likere og likere en normaldistribusjon ettersom utvalgsstørrelsen øker:

```{r}
curve(dt(x, df = 2), from = -4, to = 4, col = "blue", ylim = c(0, 0.41))
curve(dt(x, df = 5), from =-4, to = 4, col = "brown", add = TRUE)
curve(dt(x, df=20), from = -4, to = 4, col = "black", add = TRUE)
curve(dnorm, -4, 4, col = "red", add = TRUE)
legend(-4, .3, legend = c("df=2", "df=10", "df=20", "Normal"),
       col = c("blue", "brown", "black", "red"), lty = 1, cex = 1.2)
```

Så hvorfor behovet for en t-distribusjon? William Sealy Gosset, a.k.a. "Student", fant ut at hvis man ikke er helt sikker på hva standardavviket er må man bruke et estimat på standardavviket som gjør at fordelingen endrer seg litt fra normalfordelingen. Det vi omtaler som t-test er en test av en statistisk hypotese som baserer seg på Students t-distribusjon.

## One sample t-test

La oss anta at vi har en gruppe på 20 studenter som gjennomfører et nettbasert kurs i anvendt kvantitativ analyse basert på bruk av en pakke med digitale læringsressurser som legger opp til mange selvøvelser. Vi tester denne gruppa opp mot en gjennomsnittsskåre på en test på 67.5 for alle andre studenter (skåre 0-100) som har gjennomført samme kurs tidligere der man ikke har hatt samme tilgang til digitale øvingsoppgaver. Skårer denne testgruppa signifikant bedre enn resten av studentene?

```{r echo = FALSE}
ttestonesample <- read.csv("t-test_onesample.csv")
```

```{r echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE}
xfun::embed_file('t-test_onesample.csv')
```

Vi regner ut teststatstikken (t) slik:

$t=\frac{\overline{x}-\mu}{\frac{s}{\sqrt{n}}}$

der:

$t = t-verdi$

$\overline{x} = observert\ gjennomsnitt$

$\mu = teoretisk/forventet\ gjennomsnitt$

$s = standardavviket\ i\ utvalget/observerte$

$n=utvalgsstørrelse/antall\ observerte$

Vi henter nødvendige verdier fra datasettet:
```{r}
descr(ttestonesample$Score)
```

Dette gir da:

$t=\frac{72.3-67.5}{\frac{9.52}{\sqrt{20}}}=\frac{4.8}{2.129}=2.255$

Vi sammenlikner t-verdien 2.255 med kritisk verdi, f.eks. [her](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm). Vi finner verdien 1.729. Hvis t-verdien er større enn kritisk verdi: forkast nullhypotesen. Her forkaster vi nullhypotsesen fordi 2.255 er større enn 1.729. Vår alternative hypotese om at det er signifikant forskjell er styrket.

I R bruker vi:
```{r}
t.test(ttestonesample$Score, mu = 67.5, alternative = "two.sided")
```

```{r}
qt(0.05, 19, lower.tail=FALSE)
```

Vi ser også her at t-testveridien er større enn kritisk verdi (2.255 > 1.729). I tillegg ser vi at p-verdien er < 0.05 ("If p is low, the null must go"). 

### Sjekk av forutsetninger for one sample t-test

1. Tilfeldig utvalg fra en definert/gitt populasjon
2. Variabelen må være kontinuerlig
3. Populasjonen er normalfordelt

Vi ser spesielt på nr 3. Det finnes flere måter å se på normalitetsforutsetningen, både grafisk og formelle statistiske tester. Vi skal vise en formell test - Shapiro-Wilks som ofte brukes. Andre eksempler er Kolmogorov-Smirnov og Anderson-Darling. @razaliPowerComparisonsShapiroWilk2011 finner i en sammenlinende studie at Shapiro-WIlks fungerer bra.

```{r}
shapirotest <- shapiro.test(ttestonesample$Score)
shapirotest
```

Vi sammenlikner testverdien med 0,05 (gitt at vi bruker 0,05 som signifikansnivå). Dersom testverdien er over 0,05 indikerer det at dataene er normalfordelte. Hvis testeverdien er under 0,05 indikerer det at dataene avviker fra normalfordelingen. Dette er ikke tilfelle her (`r shapirotest$p.value`).

## Paired samples t-test

Paired samples t-test brukes når gruppene/målingene ikke er uavhengige av hverandre. I tilfeller hvor vi for eksempel har en gruppe som er testet to ganger på ulike tidspunkt er ikke observasjonene uavhengige av hverandre.

Paired samples t-test og one sample t-test er på en måte "samme sak" - altså, der en one sample t-test sammenlikner gjennomsnittet fra et utvalg med en kjent størrelse kalkulerer en paired samples t-test forskjellen mellom de to gjennomsnittene for deretter å gjennomføre en one sample t-test på forskjellen.

La oss anta at vi har en gruppe på 15 studenter som vi har testet to ganger. Imellom testene har de gjennomført en aktivitet som skal trigge hukommelsen.

```{r echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE}
xfun::embed_file('t-test_paired.csv')
```

```{r }
pairedsamples <- read.csv("t-test_paired.csv")
descr(pairedsamples)
```

Vi kan regne ut testverdien slik:

$t=\frac{\sum{d}}{\frac{n(\sum{d^2})-(\sum{d}^2)}{(n-1)}}$

der

$t = testverdi$

$d=differansen\ innad\ i\ hvert\ par$

$n=antall\ i\ utvalget$

Gjennom en manuell utregning finner vi $t=0.02$

Vi gjennomfører en t-test i R:

```{r}
t.test(pairedsamples$Pre, pairedsamples$Post, paired = TRUE, alternative = "two.sided")
```

Her ser vi at p er over 0,05. Dvs vi kan ikke forkaste nullhypotesen. Vi kan derfor ikke si at det er en signifikant forskjell mellom de to gruppene. 

```{r warning = FALSE}
ggpaired(pairedsamples, cond1 = "Pre", cond2 = "Post",
    fill = "condition")
```

```{r}
descr(pairedsamples)
```

Av grafen og tabellen over ser vi at spredningen er mindre etter aktiviteten (se f.eks. på standardavviket i tabellen).

```{r}
forskjell <- pairedsamples$Post - pairedsamples$Pre
shapiro.test(forskjell)
ad.test(forskjell)
jarque.bera.test(forskjell)
```

Vi kan se fra ulike tester ovenfor at forutsetningen om normalfordeling ser ut til å være innfridd. Normalt trenger vi ikke gjøre alle tre testene, men vi har tatt de med for å vise relevant kode om man skulle ha behov for den ene eller den andre - de tester normalitet fra ulike vinkler, og i svært mange tilfeller vil man se Shapiro-Wilks brukt. Robusthetstester viser også at Shapiro-Wilks viser bra robusthet og egenskaper sammenliknet med alternativer [@razaliPowerComparisonsShapiroWilk2011].

## Independent samples t-test

En vanlig situasjon er at vi har to grupper som skal sammenliknes. Hvis gruppene er uavhengige av hverandre (i motsetning til paired samples t-test), kan vi bruke independent samples t-test.

I eksempelet ønsker vi å sammenlikne to grupper studenter: en gruppe har ren nettundervisning, mens den andre gruppa har hybrid undervisning (nett og fysisk). Vi har eksamensresultater for begge gruppene. Kan vi ut fra eksamensresultatene si om gruppene er signifikant forskjellige fra hverandre?

```{r}
independent <- read.csv("t-test_independent.csv")
HeadTail <- function(independent){rbind(head(independent),tail(independent))}
HeadTail(independent)
```

Vi ser at datasettet består av 200 observasjoner av studenter som enten har gjennomført ren nettundervisning eller en hybrid undervisning (nett og fysisk undervisning).

Vi kan regne ut testverdien:

$t=\frac{\overline{x}_A - \overline{x}_B}{\sqrt{\biggl({\frac{(\sum A^2-\frac{(\sum A)^2}{n_A})+(\sum B^2-\frac{(\sum B)^2}{n_B})}{n_A+n_B-2}\biggr)}*\biggl(\frac{1}{n_A}+\frac{1}{n_B}\biggr)}}$

der:

$A = Variabel 1 - i\ vårt\ tilfelle\ "nett"$

$B = Variabel 2 - i\ vårt\ tilfelle\ "hybrid"$

$(\sum A)^2 = Summen\ av\ A'ene\ kvadrert$ 

$(\sum B)^2 = Summen\ av\ B'ene\ kvadrert$

$A_2 = Enkeltverdien\ A\ kvadrert\ (hver\ enkelt\ verdi)$

$B_2 = Enkeltverdien\ B\ kvadrert\ (hver\ enkelt\ verdi)$

$\sum A^2 = Summen\ av\ de\ kvadrerte\ A'ene$

$\sum B^2 = Summen\ av\ de\ kvadrerte\ B'ene$

$\overline{x}_A = Gjennomsnitt\ for\ variabel\ A$

$\overline{x}_B = Gjennomsnitt\ for\ variabel\ B$

$n_A = antall\ i\ variabelen\ A$

$n_B = antall\ i\ variabelen\ B$

```{r}
ttestind <- t.test(Score ~ Type, independent)
```

Vi kan legge merke til at t-testen i R velger Welch t-test i stedet for Student t-test. Forskjellen ligger i at Welch t-test ikke forutsetter lik varians, mens Student t-test gjør dette. 

```{r}
t.test(Score ~ Type, independent, var.equal=TRUE)
```

I dette eksempelet har vi ingen forskjell mellom Welch og Student t-test. Noen programmer vil automatisk gi deg den ene eller den andre, alternativt begge to. Forskjellen Forskjellen på Student’s t og Welch’s t er altså at førstnevnte forutsetter at begge gruppene har likt standardavvik ("«"the assumption of equal variances").  I virkeligheten er dette ofte ikke tilfelle (det er liten grunn til å tro at gruppene har likt standardavvik hvis de ikke har lik gjennomsnittsverdi). I slike tilfeller er Welch’s t en mer robust test. 

Ut fra testen kan vi si at det er en statistisk signifikant forskjell mellom de to gruppene. Hvis vi ser på resultatet fra testen ser vi hybridgruppa har høyere snitt enn nettgruppa. Dette forteller oss at hybridgruppa skårer signifikant høyere enn nettgruppa.
```{r}
ttestind$estimate
```


